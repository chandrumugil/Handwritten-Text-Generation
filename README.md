✍️ Handwritten Text Generation

As part of my internship at CODSOFT, this project demonstrates the use of a character-level Recurrent Neural Network (RNN) to generate handwritten-like text sequences.

🚀 Objective

To train a deep learning model that can generate realistic handwritten-style text using RNNs.

📁 Dataset

Source: Papers With Code – Handwriting Dataset

Data Type: Character-level sequences from handwritten samples

🛠️ Technologies Used

Python 3

TensorFlow / PyTorch

NumPy, Matplotlib

RNN (LSTM / GRU)

🧠 Approach

Preprocessing

Character tokenization

Sequence generation (input-output pairs)

Model Architecture

Character-level RNN (LSTM)

Softmax output layer for next character prediction

Training

Sequence-to-sequence modeling

Cross-entropy loss

Text Generation

Sampling predictions from the trained RNN
